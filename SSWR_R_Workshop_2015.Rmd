---
title: "Using R for Analytic Graphs: Learn How Data Visualization Can Improve Interpretation in Social Work Research"
date: "Saturday, November 01, 2014"
output: beamer_presentation
---

```{r, eval=FALSE, echo=FALSE}

#need to load actual parent survey data to an object called "dat"
#and estimate an actual model before this code can be run. 
#this is dat3 in methods_clean under ps_reunification 
# eps_rank <- dat[,match("eps_rank", names(dat))]
# age_eps_begin <- dat[,match("age_eps_begin", names(dat))]
# 
# age_eps_begin_par <- fitdistr(age_eps_begin, "exponential")
# age_eps_begin_sim <- floor(rexp(619, age_eps_begin_par$estimate))
# age_eps_begin_sim <- ifelse(age_eps_begin_sim <= 17
#                             ,age_eps_begin_sim
#                             ,round(runif(1,0,1),0))
# 
# eps_rank_par <- fitdistr(eps_rank, "exponential")
# eps_rank_sim <- floor(rexp(619, eps_rank_par$estimate))
# eps_rank_sim <- ifelse(eps_rank_sim <= 4 & eps_rank_sim != 0 
#                             ,eps_rank_sim
#                             ,1)
# 
# 
# #x1 <- age_eps_begin_sim           # some continuous variables 
# #x2 <- eps_rank_sim
# 
# z_adt = model$wts[6] + model$wts[7]*age_eps_begin_sim + model$wts[8]*eps_rank_sim
# z_gdn = model$wts[10] + model$wts[11]*age_eps_begin_sim + model$wts[12]*eps_rank_sim
# z_reu = model$wts[14] + model$wts[15]*age_eps_begin_sim + model$wts[16]*eps_rank_sim
# 
# pr_adt <- exp(z_adt)/rowSums(cbind(exp(z_adt), exp(z_gdn), exp(z_reu)))
# pr_gdn <- exp(z_gdn)/rowSums(cbind(exp(z_adt), exp(z_gdn), exp(z_reu)))
# pr_reu <- exp(z_reu)/rowSums(cbind(exp(z_adt), exp(z_gdn), exp(z_reu)))
# pr_enc <- 1/rowSums(cbind(exp(z_adt), exp(z_gdn), exp(z_reu)))
# 
# outcome <- rep(NA, length(pr_adt))
# for (i in 1:length(pr_adt)){
#   outcome[i] <-  sample(x = c("adt", "gdn", "reu", "enc")
#                        ,size = 1
#                        ,prob = c(pr_adt[i]
#                                  ,pr_gdn[i]
#                                  ,pr_reu[i]
#                                  ,pr_enc[i])
#                        ,replace = T) 
# }
# 
# dat <- data.frame(outcome, age_eps_begin, eps_rank)
# write.csv(dat, file = "dat.csv", fileEncoding = "macroman")
```

# Why Use R?

- Free

- Open Source

- Easy Collaboration

- Replicable Research 

# Why Wouldn't You Use R?

Steep(er) learning curve compared to, say, Excel or SPSS. This matters a lot if

- You run statistics rarely.

- You want a point and click interface. 

# Where Can you Get R?

- CRAN

- Our Thumb Drives

# Where Are We Going Today?

- Graphing Descriptive Statistics

- Graphing Model Results

# Graphing Descriptive Statistics

## What we see in the journal article...

```{r, echo=FALSE, results='asis'}
library(xtable)
library(ggplot2)
library(reshape2)
library(grid)
options(xtable.comment = FALSE)
TrocmeTab2 <- read.delim("TrocmeTab2.txt")
colnames(TrocmeTab2) <- c("Placement status", "Aboriginal (%)", "Caucasian (%)")
Table1 <- xtable(TrocmeTab2, align="llcc")
print(Table1, include.rownames=FALSE, floating=FALSE,hline.after=c(-1,0,4,nrow(Table1)))
```

# Graphing Descriptive Statistics

## What we see in the journal article...

```{r, echo=FALSE, results='asis'}
HollandTab3 <- read.delim("HollandTab3.txt")
colnames(HollandTab3) <- c("Subscale and Range", "Abbreviated item and Content", "M(+-SD)", "Item-total correlation")
Table2 <- xtable(HollandTab3, align="lllcc")
print(Table2, include.rownames=FALSE, floating=FALSE, scalebox=.7)
```

# Graphing Descriptive Statistics

## What we could see in the journal article...

```{r, echo=FALSE, results='asis'}
df10 <- read.delim("df10.txt")
#df10<-data.frame(name=var.names.order,mean=mean.vec.order,sd=sd.vec.order) #data of interest
#df10<-df10[order(nrow(df10):1),] #Invert the rows of dataset
df10$Variable<-seq(1,nrow(df10)) # Numbering index
###### Now ggplot displays the rows in this order: 7,6,5,4,3,2,1
ggplot(df10,aes(x=Variable))+
  geom_pointrange(aes(y=mean,ymin=mean-sd,ymax=mean+sd),size=1)+
  scale_x_discrete(labels=df10$name)+coord_flip()+
  theme_bw()+ylab("Score")+ theme(panel.grid.minor.y=element_blank(), panel.grid.major.y=element_blank())
```

# Graphing Model Results

## What we see in the journal article...

```{r, echo=FALSE, results='asis'}
trocmetab6 <- read.delim("trocmetab6.txt")
Table3 <- xtable(trocmetab6, align="llccc")
print(Table3, include.rownames=FALSE, floating=FALSE, scalebox=.5)
```

# Graphing Model Results

## What we could see in the journal article...

```{r, echo=FALSE, results='asis'}
tr6 <- read.delim("tr6.txt")
library(lattice)
dotplot(ord.variable ~ OR, data = tr6, main= "Predictors of Child Welfare Placement (N = 2891)",
        aspect = .9,
        xlab = list("Odds ratios",
                    cex = .75),
        scales = list(cex = .75),
        panel = function(x, y) {
          panel.abline(h = as.numeric(y), col="gray", lty=2)
          panel.xyplot(x[tr6$pvalue < .05],
                       y[tr6$pvalue < .05],
                       cex = 1.25, pch = 16, col = "black")
          panel.xyplot(x[tr6$pvalue >= .05],
                       y[tr6$pvalue >= .05],
                       cex = 1.25, pch = 1, col = "black")
          panel.abline(v = 1, lty = 2, col = "gray")
        },
        key = list(text = list(c(" Significant, p < 0.05:",
                                 "Not significant, p < .05 level:"), cex = .75),
                   points = list(pch = c(16, 1), col = "black", cex = .75),
                   space = "top", border = T) )
```

# Graphing Model Results

## What we could see in the journal article...

```{r, echo=FALSE, results='asis'}
###### Create significance variable
tr6$signif<-factor(ifelse(tr6$pvalue<=.05,1,0))
tr6<-tr6[order(-tr6$OR),] # dataset arranged from highest OR to lowest OR
######See if we index from 1 to n, the highest OR is the first on the x/y axis
######If we want the lowest OR on the first tick for x/y axis, reverse the order
tr6<-tr6[order(tr6$OR),] #Now data displays lowest to highest OR
tr6$Variable<-seq(1,nrow(tr6)) #Index 
ggplot(tr6,aes(x=OR,y=Variable))+theme_bw()+
  geom_point(aes(pch=signif))+
  geom_vline(x=1,color="grey30",linetype='dashed')+
  scale_y_discrete(labels=tr6$ord.variable)+
  scale_shape_manual(breaks=c(1,0),values=c(16,1),name="Significance",
                     labels=c("Significant: p < .05","Not significant: p >.05"))+
  theme(legend.direction="vertical",legend.position="top",legend.key=element_blank(),
        legend.key.height=unit(.5,"line"),
        panel.grid.major=element_line(color="grey50",linetype='dashed'))
```


# Graphing Model Results

## What we see in the journal article...

```{r, echo=FALSE, results='asis'}
mergeshio3 <- read.delim("mergeshio3.txt", header=FALSE)
merg_names <- c("Variable", "Coef", "SE", "p", "Coef", "SE", "p", "Coef", "SE", "p")

mergeshio3 <- mergeshio3[-1,-1]
colnames(mergeshio3) <- merg_names

Table4 <- xtable(mergeshio3)

print(Table4, include.rownames=FALSE, floating=FALSE, scalebox=.8)
```

# Graphing Model Results

## What we could see in the journal article...

```{r, echo=FALSE, results='asis'}
library(ggplot2)
########### 1. step 1 load data
########### 2. step 2 clean data and order factors
########### 3. Specify the width of your confidence intervals based on normal distribution
interval1 <- -qnorm((1-0.9)/2) # 90% multiplier
interval2 <- -qnorm((1-0.95)/2) # 95% multiplier
########### save a new datafile
###########rm(allModelFrame1,allModelFrame2)
allModelFrame1 <- read.delim("allModelFrame1.txt", header=TRUE)
allModelFrame2 <- allModelFrame1
########### reorder the data
allModelFrame2$ord.model <- factor(allModelFrame2$model, levels=c("m3", "m2", "m1"), ordered =TRUE)
zp2 <- ggplot(allModelFrame2, aes(colour = ord.model)) + 
  scale_colour_discrete(name  ="Model",
                        breaks=c("m1", "m2", "m3"),
                        labels=c("Model1", "Model2", "Model3")) +
  scale_shape_discrete(name  ="Model",
                       breaks=c("m1", "m2", "m3"),
                       labels=c("Model1", "Model2", "Model3")) 
zp2 <- zp2 + geom_hline(yintercept = 0, colour = gray(1/2), lty = 2)
zp2 <- zp2 + geom_linerange(aes(x = ord.variable, ymin = Coef - SE*interval1,
                                ymax = Coef + SE*interval1),
                            lwd = 1,position = position_dodge(width = 1/2))
zp2 <- zp2 + geom_pointrange(aes(x = ord.variable, y = Coef, ymin = Coef - SE*interval2,
                                 ymax = Coef + SE*interval2),
                             lwd = .8, position = position_dodge(width = 1/2),
                             shape = 21, fill = "BLACK")
zp2 <- zp2  + coord_flip() +theme_bw()
zp2 <- zp2 + ggtitle("Replication Shiovitz et al 2010, Table 3") +  xlab("Variables") +
  ylab("Odds Ratios") # The trick to these is position_dodge().
zp2
```

# Graphing Model Results

## What if we had more information than what was available in peer-reviewed journals?

## Consider this basic algorithm

1. Choose a counterfactual $x_c$.

2. Estimate a model to get a vector of parameters $\hat{\boldsymbol\beta}$ and the associated variance-covariance matrix, $\hat{\boldsymbol V}$.

3. Draw several $\tilde{\boldsymbol\beta}$ from $\mathcal{N}(\hat{\boldsymbol\beta},\,\hat{\boldsymbol V})$, where $\mathcal{N}$ is a mulivariate normal distribution. 

4. Calculate expected outcomes based on model parameters for all of your draws from $\mathcal{N}$. 

5. Calculate summary statistics for each level of $x_c$.

This approach will work for most of the models that social welfare researchers tend to encounter.

# A Practical Example - Background

## Research Question

How does a child's probability of exiting the foster care system vary by child characteristics?

## Multiple Permanency Outcomes

Requires that we estimate a mulinomial logistic regression model.

## Data in Question 

- 500 children entering out-of-home care in late 2007. 

- Children's parent's were surveyed once in 2007. The survey results were then linked to administrative data which faciliated a longitudinal follow-up. 

- Data have been jittered and randomly sampled from a larger set of data to mask the identity of subjects. The data used here do not reflect the data of individual subjects. 



# A practical example - Choose a counterfactual $x_c$.

## Load the data 

```{r, eval=FALSE, echo=FALSE}
# outcome <- as.factor(round(jitter(as.numeric(dat$outcome)), 0))
# levels(outcome) <- c("Adoption", "Emancipation", "Guardianship", "Reunification")
# 
# age_eps_begin <- round(jitter(as.numeric(dat$age_eps_begin), amount=1), 0)
# age_eps_begin <- ifelse(age_eps_begin < 0, dat$age_eps_begin, age_eps_begin)
# age_eps_begin <- ifelse(age_eps_begin > 17, dat$age_eps_begin, age_eps_begin)
# 
# eps_rank <- round(jitter(as.numeric(dat$eps_rank), amount=1), 0)
# eps_rank <- ifelse(eps_rank < 1, dat$eps_rank, eps_rank)
# dat <- data.frame(outcome, age_eps_begin, eps_rank)
#dat <- dat[sample(nrow(dat), 1000, replace = TRUE), ]
#write.csv(dat, file = "dat.csv", fileEncoding = "macroman")
```

```{r}
dat <- read.csv("dat.csv")
```

# A practical example - Choose a counterfactual $x_c$.

```{r, fig.width=3, fig.height=2, warning=FALSE, message=FALSE}
#looking at age of child at episode begin
require(ggplot2)
ggplot(dat, aes(x=age_eps_begin)) + 
  geom_histogram(binwidth = 1)
```

# A practical example - Choose a counterfactual $x_c$.

```{r, fig.width=6, fig.height=3, warning=FALSE, message=FALSE}
#looking at age of child at episode begin by outcome 
ggplot(dat, aes(x=age_eps_begin, fill=outcome)) + 
  geom_histogram(binwidth = 1) +
  facet_wrap(~ outcome)
```

# A practical example - Estimate a model. 

## Need to estimate a statistical model to get 

1. A vector of parameters $\hat{\boldsymbol\beta}$, and 

2. The associated variance-covariance matrix, $\hat{\boldsymbol V}$.

# A practical example - Estimate a model. 

## Prep the data

```{r, fig.width=6, fig.height=3, warning=FALSE, message=FALSE}
# easy to load external packages
# install.packages("nnet") # install once
require(nnet)             # load every time

# relevel our outcome variable
dat$outcome_rl <- relevel(dat$outcome
                          , ref = "Emancipation")

# recode to numeric
dat$outcome_rl <- as.numeric(dat$outcome_rl)
```

# A practical example - Estimate a model. 

## Run the model

```{r, warning=FALSE, message=FALSE}
# run the multinomial model
model <- multinom(outcome_rl ~ age_eps_begin + 
                   eps_rank 
                 ,data = dat
                 ,Hess = TRUE)
```


# A practical example - Estimate a model. 

## Display of summary the model

```{r, warning=FALSE, message=FALSE, }
model
```


# A practical example - Estimate a model. 

## Extract a vector of parameters $\hat{\boldsymbol\beta}$

```{r, warning=FALSE, message=FALSE}
#run the multinomial model
pe <- model$wts[c(6,7,8,10,11,12,14,15,16)]
pe[1:3]
pe[4:6]
pe[7:9]

```

# A practical example - Estimate a model. 

## Extract the associated variance-covariance matrix, $\hat{\boldsymbol V}$

```{r, warning=FALSE, message=FALSE}
#run the multinomial model
vc <- solve(model$Hess) 
```

# A practical example - Draw several $\tilde{\boldsymbol\beta}$ from $\mathcal{N}(\hat{\boldsymbol\beta},\,\hat{\boldsymbol V})$. 

```{r, warning=FALSE, message=FALSE}
#load a package which contains a multivariate normal 
#sampling function
require(MASS)
#assign a variable for the number of simulations
sims <- 10000
#draw the indicates number of beta simulates 
#using our extracted model data
simbetas <- mvrnorm(sims,pe,vc)
```


# A practical example - Last two steps...


- Calculate expected values for all of your draws from $\mathcal{N}$, and

- Calculate summary statistics for each level of $x_c$.

- Specific calculations are beyond the scope of this presentation

- But the `simcf` package from Chris Adolph (political scientist at the University of Washington) will do them for us!


# A practical example - Last two steps

## Get data read for `simcf`

- Re-arrange simulates to array format

```{r, warning=FALSE, message=FALSE}
simb <- array(NA, dim = c(sims,3,3))
simb[,,1] <- simbetas[,1:3]         
simb[,,2] <- simbetas[,4:6]
simb[,,3] <- simbetas[,7:9]
```

- Specify range of counterfactual values

```{r, warning=FALSE, message=FALSE}
agerange <- seq(0,17,by=0.1)    
```

# A practical example - Last two steps

## Get data read for `simcf`

- Load `simcf` and use the `cfFactorial()` function to set specific values for simulation. 

```{r, warning=FALSE, message=FALSE}
require(simcf)
xhyp <- cfFactorial(age = agerange
                    ,ep_rank = mean(dat$eps_rank))
```

- Run the simulation (this is where the last two steps are really performed).

```{r, warning=FALSE, message=FALSE}
test_sims <- mlogitsimev(xhyp,simb,ci=0.95)
```

# Get the data ready to graph

```{r, warning=FALSE, message=FALSE}
y <- as.vector(test_sims$pe[,1:4])

x <- rep(1:length(agerange), 4)

lower <- as.vector(test_sims$lower[,1:4,])

upper <- as.vector(test_sims$upper[,1:4,])

Outcome <- c(rep("Adoption", length(agerange))
                 ,rep("Guardianship"
                      ,length(agerange))
                 ,rep("Reunification"
                      ,length(agerange))
                 ,rep("Emancipation"
                      ,length(agerange)))
```

# Get the data ready to graph

```{r, warning=FALSE, message=FALSE}
dat_sim_plot <- data.frame(y,x,lower,upper,Outcome)
```

# Graph the data!

```{r,  warning=FALSE, message=FALSE}
p1 <- ggplot(dat_sim_plot
       ,aes(x=x/10, y=y, group=Outcome)) + 
        geom_line() 
```

# Graph the data!

```{r, warning=FALSE, message=FALSE, echo=FALSE}
p1
```

# Make it Pretty!

```{r,  warning=FALSE, message=FALSE}
p2 <- ggplot(dat_sim_plot
       ,aes(x=x/10, y=y, group=Outcome)) + 
        geom_line(size=1, alpha=.5) +
        geom_ribbon(aes(ymin=lower
                        ,ymax=upper
                        ,fill=Outcome), alpha=.5) +
        ylab("Pr(Outcome|Age,Prior Episodes)") +
        xlab("Age at Entry into Foster Care") +
        theme_bw() 
```


# Make it Pretty

```{r, warning=FALSE, message=FALSE, echo=FALSE}
p2
```
